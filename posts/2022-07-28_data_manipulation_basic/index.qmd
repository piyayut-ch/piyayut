---
title: "Grammar of Data Manipulation in R and python"
author: "Piyayut Chitchumnong"
description: | 
  A code snippet to how to implement basic data manipulation using R and python.
date: "2022-07-28"
categories: [tutorial, R, python, data-manipulation, data-wraning, data-transformation]
execute: 
  cache: false
format:
  html:
    toc: true
    toc-depth: 2
    df-print: tibble
    number-sections: true
    number-depth: 2

knitr:
  opts_chunk:
    comment: "#>" 
---

![Source: Photo by Engin Akyurt https://unsplash.com/photos/tYXBfhpZA1k](feature.jpg)

# Introduction

In this tutorial, we cover basic data manipulation operations including

- Reading data from variety of file formats.
- Selecting variables.
- Filtering rows.
- Adding new variables.
- Arranging rows by variables.
- Summarizing and Grouping.
- Reshaping data between wide and long format.
- Joining tables using key(s) variable.
- Saving data to desired file formats.

# Load packages
Both `R` and `python` are open-source and very powerful for data-related work. There are many packages and libraries that can be used, the challenge is to learn and pick the right tool to the task in hand. In this tutorial, we choose standard tools in both language.

::: {.panel-tabset}
### R
We use

- `dplyr` for data manipulation
- `tidyr` for reshaping, join data
- `readr` for read csv files
- `readxl` for read/import excel files
- `wriexl` for write/import excel files
- `arrow` for read/write parquet files
- `gapminder` example data for demonstration

```{r}
library(dplyr, warn.conflicts = FALSE)
library(tidyr)
library(readr)
library(readxl)
library(writexl)
library(arrow, warn.conflicts = FALSE)
# make sure that you have packaged installed in your machine/environments
# you can install with install.packages("<library_name>")
```

### python
We mainly use `pandas`, however additional packages required to be installed which are `openpyxl` and `pyarrow` package as we want to work with excel and parquet files.
```{python}
# make sure that you have pandas pyarrow openpyxl 
# installed in your machine/environments
# !pip install pandas openpyxl pyarrow

import pandas as pd
```
:::


# Data: gapminder
One of the important step to conduct a data analytics or machine learning project is to understand the data.

Data used in this tutorial are from `gapminder` R package inspired by famous [Hans Rosling ted's talk](https://www.youtube.com/watch?v=hVimVzgtD6w). We use two tables which are

- `gapminder` contain a data of countries from 1952 - 2007 with 3 variables including population (pop), life expectancy (LifeExp), and gdp per capita(gdpPercap).
```{r}
#| echo: false
library(gapminder)
gapminder
```

- `country_codes` contains country names and associated ISO 3166-1 country codes (alpha and numeric) will be used for join.
```{r}
#| echo: false
country_codes
```

# Reading data
There are many ways to get data into your machine for data analytics

- files i.e. excel, csv, parquet, etc.
- database
- web api
- web scraping

For the sake of simplicity, we use file approach. I will show how to read or write data in other approaches in future posts.

There are many file types, in this tutorial chooses the most common ones

- `csv`
- `excel`
- `parquet`


## csv
CSV is a text file that each columns are seperated by commas stored in `.csv` file extension. Aside from `csv`, there are similar text file that store spreadsheet data but used different seperator or fixed width to determine column by position.

::: {.panel-tabset}
### R
We use function `read_csv` from `readr` package.
```{r}
gapminder <- read_csv("gapminder.csv", show_col_types = FALSE) # readr package
gapminder
```
::: {.callout-note}
Note `<-` is convention assignment in `R`, but `=` can also be used.
:::


### python
```{python}
gapminder = pd.read_csv("gapminder.csv")
gapminder
```
:::


## excel
MS excel is a spreadsheet program and store data in `.xls` (2003 version and before) or `.xlsx`. They are not text files like `csv`, but they are a kind of binary files (XML-like) format. An excel file can contain multiple sheets and within each sheet can have multiple tables.

:::{.callout-tip}
Unstructured excel files are difficult to work with using programming. Excel are still widely used by many organizations, so at leaset, we should convince users to make a proper spreadsheet for example follow [Broman and Woo' guideline](https://www.biostat.wisc.edu/~kbroman/publications/dataorg.pdf).
:::


::: {.panel-tabset}
### R
We use function `read_excel` from `readxl` package. As an excel file can have multiple worksheets, we can read one sheet at a time and we can specify sheet to import using `sheet` argument where it could be index or sheet name.

- read fist sheet.
```{r}
gapminder <- read_excel("gapminder.xlsx")
gapminder
```

- read second sheet.
```{r}
country_codes <- read_excel("gapminder.xlsx", sheet = 2)
country_codes
```

:::{.callout-note}
Index in `R` starts with 1.
:::


### python
`pandas` has a function `read_excel` to import excel files.

- read fist sheet.
```{python}
gapminder = pd.read_excel("gapminder.xlsx")
gapminder
```

- read second sheet
```{python}
country_codes = pd.read_excel("gapminder.xlsx", sheet_name = 1)
country_codes
```

:::{.callout-note}
Index in `python` starts with 0.
:::

:::


## parquet
`Parquet` is an open file format that is great for speed and storage. Some organizeations have changed the way they sharing their data files to `parquet` instead of `csv`.

::: {.panel-tabset}
### R
We use function `read_parquet` from `arrow` package.
```{r}
gapminder <- read_parquet("gapminder.parquet")
gapminder
```

### python
`pandas` has a function `read_parquet` to import excel files.
```{python}
gapminder = pd.read_parquet("gapminder.parquet")
gapminder
```
:::


# Selecting variables
In real data wrangling work, we often get a table that contains too many variables. It is helpful to select only needed variables for further uses. In this tutorial, we select three variables inclduing `country`, `year` and `pop`.

::: {.panel-tabset}
### R
We use `select` from `dplyr` package.
```{r}
gapminder |> select(country, year, pop)
```
:::{.callout-note}
Pipe operator `|>` is an operator that take the previous object and apply it to the subsequent function as the first argument (default). We can use `|>` multiple times to the same object. This is called `chaning` This style of coding help coding more human readable as it avoids nested code. This is similar to `method chainging` in `python`.

`|>` was introduced in `R` version 4.0. Previous version used `%>%` from `magrittr`. You will see `%>%` in many tutorials or books.
:::

### python
To subset pandas, we can use `.loc` where the first argument for row, and the second argument is for columns. To select all rows used keyword `:`. To select columns, you can use character vector. 
```{python}
gapminder.loc[:, ["country", "year", "pop"]]
```
:::


# Filtering rows
We often interest in a subset of the data. There are many ways to filter data i.e. by index of rows. But one common way is to filter by conditions. In this tutorial, we want a data of Thailand since 1980 from `gapminder`.

::: {.panel-tabset}
### R
We use `filter` from `dplyr` package.
```{r}
gapminder |> filter(country == "Thailand" & year > 1980)
```

### python
We use `query` method from `pandas` package. 
```{python}
gapminder.query('country == "Thailand" & year > 1980')
```
:::{.callout-note}
`query` method argument is string. If the condition used another string, we need to use `''` and `""` to differentiate between a string used for string comparison and a string used for query arguement as a whole.
:::

:::


# Adding new variables
When we analyze data, we usually have to compute new variable(s) using original variables. In this tutorial, we compute two new vairables

- `pop_m` is population in million.
- `gdp_m` is total GDP in million USD where gdp is computed from gdpPercap multiply by pop.

::: {.panel-tabset}
### R
We use `mutate` from `dplyr` package. It can use to make multiple variables in single function call.
```{r}
gapminder |> mutate(
  pop_m = pop / 1e6,
  gdp_m = gdpPercap*pop/1e6
  )
```

### python
We use `assign` method from `pandas` package.
```{python}
gapminder.assign(
  pop_m = lambda df: df['pop']/1e6,
  gdp_m = lambda df: df['gdpPercap']*df['pop']/1e6
  )
```
:::


# Arranging rows by variables
Often, we have to sort or rearrange rows by values of particular columns to help us better understanding of data. We can sort from lower to larger (ascending) or the opposite (descending). Also multiple columns can be sorted. In this tutorial, we illustrate two cases

- sort `gapminder` by `continent` and `country` ascending.
- sort `gapminder` by `year` descending and `continent` ascending.

::: {.panel-tabset}
### R
We use `arrange` from `dplyr` package. Default mode of sorting is ascending, if we want to sort descending, use `desc(variable)` syntax.
```{r}
gapminder |> arrange(continent, country)
```

```{r}
gapminder |> arrange(desc(year), continent)
```

### python
We use `sort_values` method from `pandas` package. Default mode of sorting is ascending, if we want to sort descending, use ascending arguements.
```{python}
gapminder.sort_values(["continent", "country"])
```

```{python}
gapminder.sort_values(["year", "continent"], ascending=[True, False])
```
:::


# Summarizing and Grouping
As data is huge, we need a way or a measure that let us have a better understanding about data. One way is to condense information into some sort of summary statistics i.e. average, min, max, sum, count, etc. These operations are basically reduce the number of rows. In addition, We can summaize data by group (categorial data). In `gapminder`, we will show how to do it without group and with group(s).

## without group
We want to find population total and population mean (in millions) of all countries and from 1952 - 2007.

::: {.panel-tabset}
### R
We use `summarize` or `summarise` from `dplyr` package. It can use to make multiple summarized variables in single function call.
```{r}
gapminder |> summarize(
  pop_total_m = sum(pop)/1e6,
  pop_mean_m = mean(pop)/1e6
  )
```

### python
We use `assign` method from `pandas` package. Alternative approach is to compute each summarization.
```{python}
gapminder["pop"].agg(["sum", "mean"])/1e6

# alternative
gapminder["pop"].sum()/1e6
gapminder["pop"].mean()/1e6
```
:::

## by groups
We want to find population total and population mean (in millions) of all countries and from 1952 - 2007.

::: {.panel-tabset}
### R
We use `group_by` from `dplyr` package before use `summarize` function. The result is grouped dataframe. I normally `ungroup` it to normal dataframe.
```{r}
#| warning: false
#| message: false
gapminder |>
  group_by(continent, year) |>
  summarize(
    pop_min_m = min(pop)/1e6,
    pop_max_m = max(pop)/1e6
  ) |> ungroup()
```

### python
We use `groupby` method from `pandas` package by putting it before `agg` method. 
```{python}
gapminder.groupby(by=["continent", "year"])["pop"].agg(["min", "max"])/1e6
```
:::


# Reshaping table
Reshaping is used we want to change the way data is presenting. There are `wide` format and `long` format.

- `wide` format is a format that have more columns but less rows. Good for making report orpresenting data.
- `long` format is a format that have less columns but more rows. Good for data management, data warehousing.

We can convert back and forth as needed. For `excel` user, it is the famous pivot-table function.

## Pivot wider
Convert from long format to wide format. In this tutorial, we want to make a report of each country of life extectancy by years where we want each year to be a column. We can achieve this by pivot `gapminder` to wide format. 

::: {.panel-tabset}
### R
We use `pivot_wider` from `tidyr` package.
```{r}
gapminder |> pivot_wider(
  id_cols = c("continent", "country"), 
  names_from = "year",
  values_from = "lifeExp")
```

### python
We use `pivot` method from `pandas` package.
```{python}
gapminder.pivot(
  index = ["continent", "country"], 
  columns = "year", 
  values = "lifeExp"
  )
```
:::


## Pivot longer
Convert from wide format to long format. In this tutorial, we want to normalize `gapminder` table by moving measurment variables including `lifeExp` `pop` and `gdpPercap` columns into longer format where there is a column to store the variable name and a column store their value. We can achieve this by pivot `gapminder` to long format.

::: {.panel-tabset}
## R
We use `pivot_longer` from `tidyr` package.
```{r}
gapminder |> pivot_longer(
  cols = c("lifeExp", "pop", "gdpPercap"), 
  names_to  = "variable",
  values_to = "value")
```

## python
We use `melt` method from `pandas` package.
```{python}
gapminder.melt(
  id_vars = ["country", "continent", "year"],
  value_vars = ["lifeExp", "pop", "gdpPercap"], 
  var_name = "variable", 
  value_name = "value"
  )
```
:::


# Join tables
We join tables together to enrich data i.e. adding new variables from other table or adding metadata from reference tables. In this tutorial, we add country codes to `gapminder` dataset.

Like SQL-join, there are many types of join. In this tutorial, we illustrate left-join where the left table rows are preserved and add only matched data from right table.

::: {.panel-tabset}
### R
We use `pivot_wider` from `tidyr` package.
```{r}
gapminder |> left_join(country_codes, by = c("country" = "country"))
```

### python
We use `merge` method from `pandas` package.
```{python}

pd.merge(
  gapminder, country_codes,
  how = "left",
  left_on = "country",
  right_on = "country"
)
```

- when both tables have the same key column name, can use only argument on
```{python}
#| eval: false
pd.merge(
  gapminder, country_codes,
  how = "left",
  on = "country"
)
```

:::


# Conclusion Remarks
There are many topics that do not cover in this tutorial i.e. `date` and `datetime`, `categorial`, `text`, panel data, missing data, advance group statistics, etc. Hope this tutorial help you get start with using programming language like `R` and `python` to do data manipulation task.

## Useful resource:

- https://homepage.divms.uiowa.edu/~luke/classes/STAT4580/dplyr.html#grouped-mutate-and-filter
- https://dplyr.tidyverse.org
- https://tidyr.tidyverse.org/
- https://r4ds.had.co.nz/
- https://wesmckinney.com/book/
- https://www.rstudio.com/resources/cheatsheets/
- https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf